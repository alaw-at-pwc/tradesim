{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Price Total Quantity\n",
      "0      11.52            116\n",
      "1      11.70            165\n",
      "2      12.21             66\n",
      "3      12.68             14\n",
      "4      13.67             11\n",
      "..       ...            ...\n",
      "110  1519.65           1472\n",
      "111  1519.81            316\n",
      "112  1519.87            165\n",
      "113  1519.88             68\n",
      "114  1519.89            903\n",
      "\n",
      "[115 rows x 2 columns]\n",
      "      Price Total Quantity\n",
      "0      1.20             54\n",
      "1      1.27             51\n",
      "2      1.32             65\n",
      "3      1.34             27\n",
      "4      1.54             10\n",
      "..      ...            ...\n",
      "131   35.69             13\n",
      "132   35.93            100\n",
      "133   48.00              7\n",
      "134   64.00              7\n",
      "135  104.43             27\n",
      "\n",
      "[136 rows x 2 columns]\n",
      "   Price Total Quantity_buy Total Quantity_sell Delta Qty_Sum\n",
      "0  12.21                 66                  56    10     122\n",
      "1  12.68                 14                  12     2      26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:512: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
      "C:\\Users\\ajlaw\\AppData\\Local\\Temp\\ipykernel_33088\\3521877151.py:358: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  version_count = int(version_count + 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import participantsetup as ps\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "class auction_state:\n",
    "    def __init__(self, buy_auction_orderbook, sell_auction_orderbook):\n",
    "        buy_auction_orderbook.sort_values(by=[\"Price\", \"Timestamp\"], ascending=[False, True], inplace=True)\n",
    "        sell_auction_orderbook.sort_values(by=[\"Price\", \"Timestamp\"], ascending=[True, True], inplace=True)\n",
    "        if len(buy_auction_orderbook) > 0:\n",
    "            self.buy_orders_check = True\n",
    "            self.auction_best_bid = buy_auction_orderbook[\"Price\"].iloc[0]\n",
    "        else:\n",
    "            self.buy_orders_check = False\n",
    "            self.auction_best_bid = None\n",
    "\n",
    "        if len(sell_auction_orderbook) > 0:\n",
    "            self.sell_orders_check = True\n",
    "            self.auction_best_ask = sell_auction_orderbook[\"Price\"].iloc[0]\n",
    "        else:\n",
    "            self.sell_orders_check = False\n",
    "            self.auction_best_ask = None\n",
    "\n",
    "        if self.buy_orders_check == True and self.sell_orders_check == True:\n",
    "            self.complete_orders_check = True\n",
    "            self.priroity_gap = self.auction_best_bid - self.auction_best_ask\n",
    "            if self.priroity_gap > 0:\n",
    "                self.provisional_clear_check = \"in_excess\"\n",
    "            elif self.priroity_gap == 0:\n",
    "                self.provisional_clear_check = \"equal\"\n",
    "            elif self.priroity_gap < 0:\n",
    "                self.provisional_clear_check = \"no_clear\"\n",
    "        else:\n",
    "            self.complete_orders_check = False\n",
    "            self.priroity_gap = None\n",
    "            self.provisional_clear_check = 'no_clear'\n",
    "\n",
    "def bot_auction_logic(bot, buy_auction_orderbook, sell_auction_orderbook, open_auction_log):\n",
    "    timestamp = dt.datetime.now()\n",
    "    new_order = False\n",
    "    action = None\n",
    "    # check if orders already exist \n",
    "    open_bot_orders = open_auction_log[open_auction_log[\"Trader_ID\"] == bot[\"Trader_ID\"]]\n",
    "    open_bot_orders = open_bot_orders[open_bot_orders[\"Status\"] == \"Open\"]\n",
    "    if len(open_bot_orders) > 0:\n",
    "        for index, live_order in open_bot_orders.iterrows():    # if orders exist, look to amend, cancel, maintain, and look to maybe place new order in too\n",
    "            if live_order[\"Quantity\"] <= 0:\n",
    "                live_order[\"Quantity\"] = 1\n",
    "            figures = auction_state(buy_auction_orderbook, sell_auction_orderbook)\n",
    "            if figures.complete_orders_check == True:                                   \n",
    "                if figures.provisional_clear_check == \"in_excess\" and live_order[\"Side\"] == \"Buy\":      # if on buy side, adjust price, depending on quantity at stake, adjust\n",
    "                    wealth_ratio = bot[\"Wealth\"] / live_order[\"Quantity\"]\n",
    "                    target_qty = (bot[\"Wealth\"] / live_order[\"Price\"]) * (bot[\"Risk\"] / 10)\n",
    "                    # deciding whether to cancel or ammend order. threshold to be calibrated\n",
    "                    if target_qty - wealth_ratio > 10:\n",
    "                        action = \"Cancel\"\n",
    "                    else:\n",
    "                        action = \"Amend\"\n",
    "                        qty_gap = round((target_qty - wealth_ratio) * np.random.uniform(0.01, 1.0))\n",
    "                        new_qty = abs(live_order[\"Quantity\"] + qty_gap)\n",
    "\n",
    "                        if live_order[\"Price\"] == figures.auction_best_bid:\n",
    "                            # decreases the best_bid price\n",
    "                            price_diff = round(figures.priroity_gap * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] - price_diff\n",
    "                        else:\n",
    "                            # raise price towards best_bid    \n",
    "                            price_diff = round((figures.auction_best_bid - live_order[\"Price\"]) * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] + price_diff\n",
    "\n",
    "                elif figures.provisional_clear_check == \"in_excess\" and live_order[\"Side\"] == \"Sell\":   # if on sell side, adjust price, depending on quantity at stake, adjust         \n",
    "                    asset_ratio = bot[\"Asset\"] / live_order[\"Quantity\"]\n",
    "                    target_qty = (bot[\"Wealth\"] / live_order[\"Price\"]) * (bot[\"Risk\"] / 10)\n",
    "                    # deciding whether to cancel or ammend order. threshold to be calibrated\n",
    "                    if target_qty - asset_ratio > 10:\n",
    "                        action = \"Cancel\"\n",
    "                    else:\n",
    "                        action = \"Amend\"    \n",
    "                        qty_gap = round((target_qty - asset_ratio) * np.random.uniform(0.01, 1.0))\n",
    "                        new_qty = abs(live_order[\"Quantity\"] + qty_gap)\n",
    "\n",
    "                        if live_order[\"Price\"] == figures.auction_best_ask:\n",
    "                            # increases the best_ask price\n",
    "                            price_diff = round(figures.priroity_gap * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] + price_diff\n",
    "                        else:\n",
    "                            # lower price towards best_ask  \n",
    "                            price_diff = round((live_order[\"Price\"] - figures.auction_best_ask) * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] - price_diff\n",
    "\n",
    "                elif figures.provisional_clear_check == \"equal\":                                        # depending on quantity at stake, adjust\n",
    "                    wealth_ratio = bot[\"Wealth\"] / live_order[\"Quantity\"]\n",
    "                    target_qty = (bot[\"Wealth\"] / live_order[\"Price\"]) * (bot[\"Risk\"] / 10)\n",
    "                    qty_gap = round((target_qty - wealth_ratio) * np.random.uniform(0.01, 1.0))\n",
    "                    new_qty = abs(live_order[\"Quantity\"] + qty_gap)\n",
    "                    new_price = live_order[\"Price\"]\n",
    "                    action = None\n",
    "\n",
    "                elif figures.provisional_clear_check == \"no_clear\" and live_order[\"Side\"] == \"Buy\":     # if on buy side, adjust price, depending on quantity at stake, adjust\n",
    "                    wealth_ratio = bot[\"Wealth\"] / live_order[\"Quantity\"]\n",
    "                    target_qty = (bot[\"Wealth\"] / live_order[\"Price\"]) * (bot[\"Risk\"] / 10)\n",
    "                    # deciding whether to cancel or ammend order. threshold to be calibrated\n",
    "                    if target_qty - wealth_ratio > 10:\n",
    "                        action = \"Cancel\"\n",
    "                    else:\n",
    "                        action = \"Amend\"\n",
    "                        qty_gap = round((target_qty - wealth_ratio) * np.random.uniform(0.01, 1.0))\n",
    "                        new_qty = abs(live_order[\"Quantity\"] + qty_gap)\n",
    "\n",
    "                        if live_order[\"Price\"] == figures.auction_best_bid:\n",
    "                            # increases the best_bid price\n",
    "                            price_diff = round(figures.priroity_gap * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] - price_diff\n",
    "                        else:\n",
    "                            # raise price towards best_bid    \n",
    "                            price_diff = round((figures.auction_best_bid - live_order[\"Price\"]) * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] - price_diff\n",
    "\n",
    "                elif figures.provisional_clear_check== \"no_clear\" and live_order[\"Side\"] == \"Sell\":    # if on sell side, adjust price, depending on quantity at stake, adjust\n",
    "                    asset_ratio = bot[\"Asset\"] / live_order[\"Quantity\"]\n",
    "                    target_qty = (bot[\"Wealth\"] / live_order[\"Price\"]) * (bot[\"Risk\"] / 10)\n",
    "                    # deciding whether to cancel or ammend order. threshold to be calibrated\n",
    "                    if target_qty - asset_ratio > 10:\n",
    "                        action = \"Cancel\"\n",
    "                    else:\n",
    "                        action = \"Amend\"    \n",
    "                        qty_gap = round((target_qty - asset_ratio) * np.random.uniform(0.01, 1.0))\n",
    "                        new_qty = abs(live_order[\"Quantity\"] + qty_gap)\n",
    "\n",
    "                        if live_order[\"Price\"] == figures.auction_best_ask:\n",
    "                            # decreases the best_ask price\n",
    "                            price_diff = round(figures.priroity_gap * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] + price_diff\n",
    "                        else:\n",
    "                            # lower price towards best_ask  \n",
    "                            price_diff = round((live_order[\"Price\"] - figures.auction_best_ask) * np.random.uniform(0.1, 1.0), 2)\n",
    "                            new_price = live_order[\"Price\"] + price_diff\n",
    "\n",
    "                if action == \"Amend\":\n",
    "                    # updating stale order within the orderbook log\n",
    "                    amend_time = dt.datetime.now()\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[index, update_cols] = [\"Order Amend\", amend_time]\n",
    "                    # writng new price and qty to orderbook log\n",
    "                    try:\n",
    "                        version_count = open_auction_log.loc[index, \"Version\"]\n",
    "                        version_count = int(version_count + 1)\n",
    "                    except:\n",
    "                        version_count = 2\n",
    "                    to_log = pd.Series({\"Order_ID\": live_order[\"Order_ID\"], \"Trader_ID\" : live_order[\"Trader_ID\"], \"Timestamp\" : amend_time, \"Quantity\" : new_qty, \"Price\" : new_price, \"Side\": \"Buy\", \"Status\": \"Open\", \"Update_Timestamp\": amend_time, \"Version\": version_count})\n",
    "                    open_auction_log = pd.concat([open_auction_log, to_log.to_frame().T], ignore_index=True)\n",
    "                    new_price = round(new_price, 2)\n",
    "                    if new_qty <= 0:\n",
    "                        new_qty = 1\n",
    "                    new_qty = round(new_qty)\n",
    "                    \n",
    "                    # updating the live orderbook\n",
    "                    if live_order[\"Side\"] == \"Buy\":\n",
    "                        buy_auction_orderbook.loc[buy_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"], \"Timestamp\"] = amend_time\n",
    "                        buy_auction_orderbook.loc[buy_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"], \"Price\"] = new_price\n",
    "                        buy_auction_orderbook.loc[buy_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"], \"Quantity\"] = new_qty\n",
    "                    elif live_order[\"Side\"] == \"Sell\":\n",
    "                        sell_auction_orderbook.loc[sell_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"], \"Timestamp\"] = amend_time\n",
    "                        sell_auction_orderbook.loc[sell_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"], \"Price\"] = new_price\n",
    "                        sell_auction_orderbook.loc[sell_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"], \"Quantity\"] = new_qty         \n",
    "                    new_order == False\n",
    "                \n",
    "                elif action == \"Cancel\":\n",
    "                    # updating orderbook log with the cancel\n",
    "                    cancel_time = dt.datetime.now()\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[index, update_cols] = [\"Cancelled\", cancel_time]\n",
    "\n",
    "                    # removing order from live orderbook\n",
    "                    if live_order[\"Side\"] == \"Buy\":\n",
    "                        buy_auction_orderbook.drop(buy_auction_orderbook[buy_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"]].index, inplace=True)\n",
    "                    elif live_order[\"Side\"] == \"Sell\":\n",
    "                        sell_auction_orderbook.drop(sell_auction_orderbook[sell_auction_orderbook[\"Order_ID\"] == live_order[\"Order_ID\"]].index, inplace=True)\n",
    "                    new_order == True\n",
    "\n",
    "        else:                                                                       # if bot has no orders in the market, do basic decision\n",
    "            # sets the order ID\n",
    "            if len(open_auction_log) < 1:                                       \n",
    "                order_id = 1\n",
    "            else:\n",
    "                order_id = int(open_auction_log.iloc[-1,0] + 1) \n",
    "\n",
    "            # benchmark to decide the side\n",
    "            wealth_asset_ratio = bot[\"Wealth\"] / bot[\"Asset\"] \n",
    "            if wealth_asset_ratio >= 11:\n",
    "                order_price = round(wealth_asset_ratio, 2)\n",
    "                order_quantity = round((bot[\"Wealth\"] / order_price) * bot[\"Risk\"]) + 1\n",
    "\n",
    "                # append order to live log and historic log\n",
    "                order = pd.Series({\"Order_ID\": order_id, \"Trader_ID\" : bot[\"Trader_ID\"], \"Timestamp\" : timestamp, \"Quantity\" : order_quantity, \"Price\" : order_price})\n",
    "                buy_auction_orderbook = pd.concat([buy_auction_orderbook, order.to_frame().T], ignore_index=True)\n",
    "                to_log = pd.Series({\"Order_ID\": order[\"Order_ID\"], \"Trader_ID\" : order[\"Trader_ID\"], \"Timestamp\" : order[\"Timestamp\"], \"Quantity\" : order[\"Quantity\"], \"Price\" : order[\"Price\"], \"Side\": \"Buy\", \"Status\": \"Open\", \"Update_Timestamp\": order[\"Timestamp\"], \"Version\": 1})\n",
    "                open_auction_log = pd.concat([open_auction_log, to_log.to_frame().T], ignore_index=True)\n",
    "\n",
    "            elif wealth_asset_ratio < 11:\n",
    "                order_quantity = round(bot[\"Asset\"] * bot[\"Risk\"]) + 1\n",
    "                order_price = round(bot[\"Asset\"] / order_quantity, 2) \n",
    "\n",
    "                # append order to live log and historic log\n",
    "                order = pd.Series({\"Order_ID\": order_id, \"Trader_ID\" : bot[\"Trader_ID\"], \"Timestamp\" : timestamp, \"Quantity\" : order_quantity, \"Price\" : order_price})\n",
    "                sell_auction_orderbook = pd.concat([sell_auction_orderbook, order.to_frame().T], ignore_index=True)\n",
    "                to_log = pd.Series({\"Order_ID\": order[\"Order_ID\"], \"Trader_ID\" : order[\"Trader_ID\"], \"Timestamp\" : order[\"Timestamp\"], \"Quantity\" : order[\"Quantity\"], \"Price\" : order[\"Price\"], \"Side\": \"Sell\", \"Status\": \"Open\", \"Update_Timestamp\": order[\"Timestamp\"], \"Version\": 1})\n",
    "                open_auction_log = pd.concat([open_auction_log, to_log.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    # RP - Bernoulli risk probability test to place another order into the auction:\n",
    "    # H0: bot will not place a new order \n",
    "    # H1: bot will place a new order - high risk option\n",
    "    test_val = np.random.random()\n",
    "    if test_val > bot[\"Risk\"]:  \n",
    "        new_order = True\n",
    "\n",
    "    # placing a new order if flagged to do so \n",
    "    if new_order == True:\n",
    "        # sets the order ID\n",
    "        if len(open_auction_log) < 1:                                       \n",
    "                order_id = 1\n",
    "        else:\n",
    "            order_id = int(open_auction_log.iloc[-1,0] + 1)  \n",
    "        # benchmark to decide the side\n",
    "        wealth_asset_ratio = bot[\"Wealth\"] / bot[\"Asset\"] \n",
    "        if wealth_asset_ratio >= 11:\n",
    "            order_price = round(wealth_asset_ratio, 2) \n",
    "            order_quantity = round((bot[\"Wealth\"] / order_price) * (bot[\"Risk\"]/2)) + 1 # quantity at half\n",
    "\n",
    "            # append order to live log and historic log\n",
    "            order = pd.Series({\"Order_ID\": order_id, \"Trader_ID\" : bot[\"Trader_ID\"], \"Timestamp\" : timestamp, \"Quantity\" : order_quantity, \"Price\" : order_price})\n",
    "            buy_auction_orderbook = pd.concat([buy_auction_orderbook, order.to_frame().T], ignore_index=True)\n",
    "            to_log = pd.Series({\"Order_ID\": order[\"Order_ID\"], \"Trader_ID\" : order[\"Trader_ID\"], \"Timestamp\" : order[\"Timestamp\"], \"Quantity\" : order[\"Quantity\"], \"Price\" : order[\"Price\"], \"Side\": \"Buy\", \"Status\": \"Open\", \"Update_Timestamp\": order[\"Timestamp\"], \"Version\": 1})\n",
    "            open_auction_log = pd.concat([open_auction_log, to_log.to_frame().T], ignore_index=True)\n",
    "\n",
    "        elif wealth_asset_ratio < 11:\n",
    "            order_quantity = round(bot[\"Asset\"] * (bot[\"Risk\"]/2)) + 1  # quantity at half\n",
    "            order_price = round(bot[\"Asset\"] / order_quantity, 2)\n",
    "\n",
    "            # append order to live log and historic log\n",
    "            order = pd.Series({\"Order_ID\": order_id, \"Trader_ID\" : bot[\"Trader_ID\"], \"Timestamp\" : timestamp, \"Quantity\" : order_quantity, \"Price\" : order_price})\n",
    "            sell_auction_orderbook = pd.concat([sell_auction_orderbook, order.to_frame().T], ignore_index=True)\n",
    "            to_log = pd.Series({\"Order_ID\": order[\"Order_ID\"], \"Trader_ID\" : order[\"Trader_ID\"], \"Timestamp\" : order[\"Timestamp\"], \"Quantity\" : order[\"Quantity\"], \"Price\" : order[\"Price\"], \"Side\": \"Sell\", \"Status\": \"Open\", \"Update_Timestamp\": order[\"Timestamp\"], \"Version\": 1})\n",
    "            open_auction_log = pd.concat([open_auction_log, to_log.to_frame().T], ignore_index=True)\n",
    "            \n",
    "    # Sorting the orderbooks \n",
    "    buy_auction_orderbook.sort_values(by=[\"Price\", \"Timestamp\"], ascending=[False, True], inplace=True)\n",
    "    sell_auction_orderbook.sort_values(by=[\"Price\", \"Timestamp\"], ascending=[True, True], inplace=True)\n",
    "    open_auction_log.sort_values(by=[\"Order_ID\", \"Version\"], ascending=[True, True], inplace=True)\n",
    "\n",
    "    return buy_auction_orderbook, sell_auction_orderbook, open_auction_log\n",
    "\n",
    "# function that manages the clearing of orders, and credits and debits accordingly\n",
    "def matching_logic(df_participants, buy_orders, sell_orders, type_clear, open_auction_log):\n",
    "    timestamp = dt.datetime.now()\n",
    "    transaction_log = pd.DataFrame(columns=[\"Timestamp\", \"Buy_Side_Order_ID\", \"Buy_Side_Trader_ID\", \"Sell_Side_Order_ID\", \"Sell_Side_Trader_ID\", \"Quantity\", \"Price\"]) \n",
    "    def transaction_append (transaction_log, timestamp, buy_order_id, buy_id, sell_order_id, sell_id, quantity, price):\n",
    "        quantity = int(quantity)\n",
    "        price = float(price)\n",
    "        transaction = pd.Series({\n",
    "            \"Timestamp\" : timestamp, \n",
    "            \"Buy_Side_Order_ID\" : int(buy_order_id),\n",
    "            \"Buy_Side_Trader_ID\" : int(buy_id), \n",
    "            \"Sell_Side_Order_ID\" : int(sell_order_id),\n",
    "            \"Sell_Side_Trader_ID\" : int(sell_id), \n",
    "            \"Quantity\" : quantity, \n",
    "            \"Price\" : price})\n",
    "        transaction_log = pd.concat([transaction_log, transaction.to_frame().T], ignore_index=True)\n",
    "        transaction_log[\"Timestamp\"] = pd.to_datetime(transaction_log[\"Timestamp\"])\n",
    "        transaction_log.sort_values(by=[\"Timestamp\"], ascending=[True], inplace=True)\n",
    "        return transaction_log\n",
    "    \n",
    "    def debit_credit (df_participants, buy_id, sell_id, quantity, price):\n",
    "        transaction_val = round(quantity * price, 2)\n",
    "        df_participants.loc[df_participants[\"Trader_ID\"] == buy_id, \"Wealth\"] -= transaction_val\n",
    "        df_participants.loc[df_participants[\"Trader_ID\"] == buy_id, \"Asset\"] += quantity\n",
    "        df_participants.loc[df_participants[\"Trader_ID\"] == sell_id, \"Wealth\"] += transaction_val\n",
    "        df_participants.loc[df_participants[\"Trader_ID\"] == sell_id, \"Asset\"] -= quantity\n",
    "        return df_participants\n",
    "    \n",
    "    if type_clear == \"equal\" or \"buy_excess\":\n",
    "        for index, sell_order in sell_orders.iterrows():\n",
    "            sell_quantity = sell_order[\"Quantity\"]\n",
    "\n",
    "            # Pull best bid info\n",
    "            buy_id = buy_orders['Trader_ID'].iloc[0]\n",
    "            buy_order_id = buy_orders['Order_ID'].iloc[0]\n",
    "            buy_qty = buy_orders['Quantity'].iloc[0]\n",
    "            result = sell_quantity - buy_qty        \n",
    "            while sell_quantity > 0:\n",
    "                if result > 0:\n",
    "                    # writing the transaction, and debiting and crediting accordingly\n",
    "                    transaction_log = transaction_append(transaction_log, timestamp, buy_order_id, buy_id, sell_order[\"Order_ID\"], sell_order[\"Trader_ID\"], buy_qty, sell_order[\"Price\"])\n",
    "                    df_participants = debit_credit(df_participants, buy_id, sell_order[\"Trader_ID\"], buy_qty, sell_order[\"Price\"])\n",
    "\n",
    "                    # updating buy order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == buy_order_id) & (open_auction_log[\"Quantity\"] == buy_qty)].index\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "                    # updating sell order in the logs\n",
    "                    stale_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == sell_order[\"Order_ID\"]) & (open_auction_log[\"Quantity\"] == sell_order[\"Quantity\"])].index\n",
    "                    open_auction_log.loc[stale_order_index, update_cols] = [\"Order Matched - Partial Fill\", timestamp]\n",
    "                    try:\n",
    "                        version_count = open_auction_log.loc[stale_order_index, \"Version\"]\n",
    "                        version_count = int(version_count + 1)  \n",
    "                    except:\n",
    "                        version_count = 2\n",
    "                    child_order = pd.Series({\n",
    "                        \"Order_ID\": sell_order[\"Order_ID\"], \n",
    "                        \"Trader_ID\" : int(sell_order[\"Trader_ID\"]), \n",
    "                        \"Timestamp\" : timestamp, \n",
    "                        \"Quantity\" : result, \n",
    "                        \"Price\" : float(sell_order[\"Price\"]), \n",
    "                        \"Side\": \"Sell\", \n",
    "                        \"Status\": \"Open\", \n",
    "                        \"Update_Timestamp\": timestamp, \n",
    "                        \"Version\": version_count\n",
    "                    })\n",
    "                    open_auction_log = pd.concat([open_auction_log, child_order.to_frame().T], ignore_index=True)\n",
    "                    # removing cleared order from buy orderbook\n",
    "                    buy_orders = buy_orders.iloc[1:]\n",
    "                    buy_orders.reset_index(drop = True, inplace=True)\n",
    "                    sell_quantity = result # reset order_quantity to new level\n",
    "                    result = sell_quantity - buy_qty \n",
    "\n",
    "                elif result == 0:\n",
    "                    transaction_log = transaction_append(transaction_log, timestamp, buy_order_id, buy_id, sell_order[\"Order_ID\"], sell_order[\"Trader_ID\"], buy_qty, sell_order[\"Price\"])\n",
    "                    df_participants = debit_credit(df_participants, buy_id, sell_order[\"Trader_ID\"], buy_qty, sell_order[\"Price\"])\n",
    "\n",
    "                    # updating buy order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == buy_order_id) & (open_auction_log[\"Quantity\"] == buy_qty)].index\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "                    buy_orders = buy_orders.iloc[1:]\n",
    "                    buy_orders.reset_index(drop = True, inplace=True)\n",
    "                    # updating sell order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == sell_order[\"Order_ID\"]) & (open_auction_log[\"Quantity\"] == sell_order[\"Quantity\"])].index\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "                    sell_quantity = 0\n",
    "                    break\n",
    "\n",
    "                elif result < 0:\n",
    "                    transaction_log = transaction_append(transaction_log, timestamp, buy_order_id, buy_id, sell_order[\"Order_ID\"], sell_order[\"Trader_ID\"], sell_order[\"Quantity\"], sell_order[\"Price\"])\n",
    "                    df_participants = debit_credit(df_participants, buy_id, sell_order[\"Trader_ID\"], sell_order[\"Quantity\"], sell_order[\"Price\"])\n",
    "\n",
    "                    # update sell order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == sell_order[\"Order_ID\"]) & (open_auction_log[\"Quantity\"] == sell_order[\"Quantity\"])].index\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "\n",
    "                    # updating partially filled buy order    \n",
    "                    new_buy_qty = buy_qty - sell_quantity\n",
    "                    stale_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == buy_order_id) & (open_auction_log[\"Quantity\"] == buy_qty)].index\n",
    "                    open_auction_log.loc[stale_order_index, update_cols] = [\"Order Matched - Partial Fill\", timestamp]\n",
    "                    try:\n",
    "                        version_count = open_auction_log.loc[stale_order_index, \"Version\"]\n",
    "                        version_count = int(version_count + 1)  \n",
    "                    except:\n",
    "                        version_count = 2\n",
    "                    child_order = pd.Series({\n",
    "                        \"Order_ID\": buy_order_id, \n",
    "                        \"Trader_ID\" : int(buy_id), \n",
    "                        \"Timestamp\" : timestamp, \n",
    "                        \"Quantity\" : new_buy_qty, \n",
    "                        \"Price\" : float(sell_order[\"Price\"]), \n",
    "                        \"Side\": \"Buy\", \n",
    "                        \"Status\": \"Open\", \n",
    "                        \"Update_Timestamp\": timestamp, \n",
    "                        \"Version\": version_count\n",
    "                    })\n",
    "                    open_auction_log = pd.concat([open_auction_log, child_order.to_frame().T], ignore_index=True)\n",
    "                    # amending quantity within the order book\n",
    "                    update_buyorder_index = buy_orders[(buy_orders[\"Order_ID\"] == buy_order_id)].index\n",
    "                    buy_orders.loc[update_buyorder_index,\"Quantity\"] = new_buy_qty\n",
    "                    sell_quantity = 0\n",
    "                    break\n",
    "                try:\n",
    "                    buy_id = buy_orders['Trader_ID'].iloc[0]\n",
    "                    buy_order_id = buy_orders['Order_ID'].iloc[0]\n",
    "                    buy_qty = buy_orders['Quantity'].iloc[0]\n",
    "                    result = sell_quantity - buy_qty  \n",
    "                except:\n",
    "                    break\n",
    "\n",
    "    elif type_clear == \"sell_excess\":\n",
    "        for index, buy_order in buy_orders.iterrows():\n",
    "            buy_quantity = buy_order[\"Quantity\"]\n",
    "\n",
    "            # Pull best bid info\n",
    "            sell_id = sell_orders['Trader_ID'].iloc[0]\n",
    "            sell_order_id = sell_orders['Order_ID'].iloc[0]\n",
    "            sell_qty = sell_orders['Quantity'].iloc[0]\n",
    "            result = buy_quantity - sell_qty        \n",
    "            while buy_quantity > 0:\n",
    "                if result > 0:\n",
    "                    # writing the transaction, and debiting and crediting accordingly\n",
    "                    transaction_log = transaction_append(transaction_log, timestamp, buy_order[\"Order_ID\"], buy_order[\"Trader_ID\"], sell_order_id, sell_id, sell_qty, buy_order[\"Price\"])\n",
    "                    df_participants = debit_credit(df_participants, buy_order[\"Trader_ID\"], sell_id, sell_qty, buy_order[\"Price\"])\n",
    "\n",
    "                    # updating sell order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == sell_order_id) & (open_auction_log[\"Quantity\"] == sell_qty)].index\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "                    # updating buy order in the logs\n",
    "                    stale_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == buy_order[\"Order_ID\"]) & (open_auction_log[\"Quantity\"] == buy_order[\"Quantity\"])].index\n",
    "                    open_auction_log.loc[stale_order_index, update_cols] = [\"Order Matched - Partial Fill\", timestamp]\n",
    "                    try:\n",
    "                        version_count = open_auction_log.loc[stale_order_index, \"Version\"]\n",
    "                        version_count = int(version_count + 1)  \n",
    "                    except:\n",
    "                        version_count = 2\n",
    "                    child_order = pd.Series({\n",
    "                        \"Order_ID\": buy_order[\"Order_ID\"], \n",
    "                        \"Trader_ID\" : int(buy_order[\"Trader_ID\"]), \n",
    "                        \"Timestamp\" : timestamp, \n",
    "                        \"Quantity\" : result, \n",
    "                        \"Price\" : float(buy_order[\"Price\"]), \n",
    "                        \"Side\": \"Buy\", \n",
    "                        \"Status\": \"Open\", \n",
    "                        \"Update_Timestamp\": timestamp, \n",
    "                        \"Version\": version_count\n",
    "                    })\n",
    "                    open_auction_log = pd.concat([open_auction_log, child_order.to_frame().T], ignore_index=True)\n",
    "                    # removing cleared order from sell orderbook\n",
    "                    sell_orders = sell_orders.iloc[1:]\n",
    "                    sell_orders.reset_index(drop = True, inplace=True)\n",
    "                    buy_quantity = result # reset order_quantity to new level\n",
    "                    result = buy_quantity - sell_qty \n",
    "\n",
    "                elif result == 0:\n",
    "                    transaction_log = transaction_append(transaction_log, timestamp, buy_order[\"Order_ID\"], buy_order[\"Trader_ID\"], sell_order_id, sell_id, sell_qty, buy_order[\"Price\"])\n",
    "                    df_participants = debit_credit(df_participants, buy_order[\"Trader_ID\"], sell_id, sell_qty, buy_order[\"Price\"])\n",
    "\n",
    "                    # updating sell order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == sell_order_id) & (open_auction_log[\"Quantity\"] == sell_qty)].index\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "                    buy_orders = buy_orders.iloc[1:]\n",
    "                    buy_orders.reset_index(drop = True, inplace=True)\n",
    "                    # updating buy order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == buy_order[\"Order_ID\"]) & (open_auction_log[\"Quantity\"] == buy_order[\"Quantity\"])].index\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "                    buy_quantity = 0\n",
    "                    break\n",
    "\n",
    "                elif result < 0:\n",
    "                    transaction_log = transaction_append(transaction_log, timestamp, buy_order[\"Order_ID\"], buy_order[\"Trader_ID\"], sell_order_id, sell_id, buy_order[\"Quantity\"], buy_order[\"Price\"])\n",
    "                    df_participants = debit_credit(df_participants, buy_order[\"Trader_ID\"], sell_id, sell_qty, buy_order[\"Price\"])\n",
    "\n",
    "                    # update buy order in the logs\n",
    "                    cleared_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == buy_order[\"Order_ID\"]) & (open_auction_log[\"Quantity\"] == buy_order[\"Quantity\"])].index\n",
    "                    update_cols = [\"Status\", \"Update_Timestamp\"]\n",
    "                    open_auction_log.loc[cleared_order_index, update_cols] = [\"Order Matched\", timestamp]\n",
    "\n",
    "                    # updating partially filled buy order    \n",
    "                    new_sell_qty = sell_qty - buy_quantity\n",
    "                    stale_order_index = open_auction_log[(open_auction_log[\"Order_ID\"] == sell_order_id) & (open_auction_log[\"Quantity\"] == sell_qty)].index\n",
    "                    open_auction_log.loc[stale_order_index, update_cols] = [\"Order Matched - Partial Fill\", timestamp]\n",
    "                    try:\n",
    "                        version_count = open_auction_log.loc[stale_order_index, \"Version\"]\n",
    "                        version_count = int(version_count + 1)  \n",
    "                    except:\n",
    "                        version_count = 2\n",
    "                    child_order = pd.Series({\n",
    "                        \"Order_ID\": sell_order_id, \n",
    "                        \"Trader_ID\" : int(sell_id), \n",
    "                        \"Timestamp\" : timestamp, \n",
    "                        \"Quantity\" : new_sell_qty, \n",
    "                        \"Price\" : float(buy_order[\"Price\"]), \n",
    "                        \"Side\": \"Sell\", \n",
    "                        \"Status\": \"Open\", \n",
    "                        \"Update_Timestamp\": timestamp, \n",
    "                        \"Version\": version_count\n",
    "                    })\n",
    "                    open_auction_log = pd.concat([open_auction_log, child_order.to_frame().T], ignore_index=True)\n",
    "                    # amending quantity within the order book\n",
    "                    update_sellorder_index = sell_orders[(sell_orders[\"Order_ID\"] == sell_order_id)].index\n",
    "                    sell_orders.loc[update_sellorder_index,\"Quantity\"] = new_sell_qty\n",
    "                    buy_quantity = 0\n",
    "                    break\n",
    "                try:\n",
    "                    sell_id = sell_orders['Trader_ID'].iloc[0]\n",
    "                    sell_order_id = sell_orders['Order_ID'].iloc[0]\n",
    "                    sell_qty = sell_orders['Quantity'].iloc[0]\n",
    "                    result = buy_quantity - sell_qty  \n",
    "                except:\n",
    "                    break\n",
    "    return df_participants, transaction_log, open_auction_log\n",
    "\n",
    "df_participants = ps.participant_creation(100, 'high')\n",
    "df_participants = df_participants.astype({\"Trader_ID\":int, \"Asset\":float, \"Wealth\":float, \"Risk\":float, \"Activity\":float, \"Delay\":int, \"Profile\":str, \"PreAsset\":float, \"PreWealth\":float})\n",
    "\n",
    "#start_price, open_auction_log, auction_transaction_log, df_participants = open_auction(df_participants)\n",
    "\n",
    "# setup of auction orderbooks and logs \n",
    "buy_auction_orderbook = pd.DataFrame(columns=[\"Order_ID\", \"Trader_ID\", \"Timestamp\", \"Quantity\", \"Price\"])\n",
    "sell_auction_orderbook = pd.DataFrame(columns=[\"Order_ID\", \"Trader_ID\", \"Timestamp\", \"Quantity\", \"Price\"])\n",
    "open_auction_log = pd.DataFrame(columns=[\"Order_ID\", \"Trader_ID\", \"Timestamp\", \"Quantity\", \"Price\", \"Side\", \"Status\", \"Update_Timestamp\", \"Version\"])\n",
    "\n",
    "# setting the length of the auction call period \n",
    "current_time = time.time()\n",
    "\n",
    "auction_end = current_time + 30\n",
    "# call period loop, where bots place orders into market\n",
    "while current_time < auction_end:\n",
    "    current_time = time.time()\n",
    "    df_available = ps.iteration_start(df_participants) \n",
    "    for index, bot in df_available.iterrows():\n",
    "        # run bot logic that decides price level and quantity for the order\n",
    "        buy_auction_orderbook, sell_auction_orderbook, open_auction_log = bot_auction_logic(bot, buy_auction_orderbook, sell_auction_orderbook, open_auction_log)\n",
    "        delay = round((1/bot[\"Activity\"]) * abs(np.random.randint(1,20)))\n",
    "        bot[\"Delay\"] = delay + 1\n",
    "    if len(df_available) > 0:\n",
    "        merged_df = df_participants.merge(df_available, on=\"Trader_ID\", how='left', suffixes   =('_old', '_new'))\n",
    "        merged_df['Delay'] = merged_df['Delay_new'].fillna(merged_df['Delay_old']).infer_objects(copy=False)\n",
    "        merged_df.drop(['Delay_old','Delay_new'], axis=1, inplace=True)\n",
    "        merged_df['Trader_ID'] = merged_df['Trader_ID'].astype(int)\n",
    "        df_participants.update(merged_df)\n",
    "    # reset time\n",
    "    df_participants[\"Delay\"] = df_participants[\"Delay\"].apply(lambda x: abs(x - 1))\n",
    "    df_participants[\"Wealth\"] = df_participants[\"Wealth\"].apply(lambda x: round(x, 2))     \n",
    "# once call period has ended, find clearing price, and credit and debit bots accordingly \n",
    "buy_agg_orderbook = pd.DataFrame(columns=[\"Price\", \"Quantity\"])\n",
    "buy_agg_orderbook = buy_auction_orderbook.groupby(\"Price\").agg({\"Quantity\" : 'sum'}).reset_index()\n",
    "buy_agg_orderbook.columns = ['Price', 'Total Quantity']\n",
    "buy_auction_orderbook.sort_values(by=[\"Price\"], ascending=False, inplace=True)\n",
    "print(buy_agg_orderbook)\n",
    "\n",
    "sell_agg_orderbook = pd.DataFrame(columns=[\"Price\", \"Quantity\"])\n",
    "sell_agg_orderbook = sell_auction_orderbook.groupby(\"Price\").agg({\"Quantity\" : 'sum'}).reset_index()\n",
    "sell_agg_orderbook.columns = ['Price', 'Total Quantity']\n",
    "sell_auction_orderbook.sort_values(by=[\"Price\"], ascending=True, inplace=True)\n",
    "print(sell_agg_orderbook)\n",
    "\n",
    "# finds the only price levels that are present in both buy and sell orderbooks\n",
    "aggregated_orderbooks = buy_agg_orderbook.merge(sell_agg_orderbook, how='inner', on='Price', suffixes=('_buy', '_sell'))\n",
    "aggregated_orderbooks[\"Delta\"] = abs(aggregated_orderbooks[\"Total Quantity_buy\"] - aggregated_orderbooks[\"Total Quantity_sell\"])\n",
    "aggregated_orderbooks[\"Qty_Sum\"] = aggregated_orderbooks[\"Total Quantity_buy\"] + aggregated_orderbooks[\"Total Quantity_sell\"]\n",
    "aggregated_orderbooks.sort_values(by=[\"Qty_Sum\", \"Delta\"], ascending=[False, True], inplace=True)\n",
    "print(aggregated_orderbooks)\n",
    "clearing_price = aggregated_orderbooks[\"Price\"].iloc[0]\n",
    "\n",
    "# extract orders to only those that can be cleared\n",
    "available_buy_orders = buy_auction_orderbook[\"Price\"] == clearing_price\n",
    "available_sell_orders = sell_auction_orderbook[\"Price\"] == clearing_price\n",
    "to_clear_buy_orders = buy_auction_orderbook[available_buy_orders].sort_values(by=[\"Timestamp\"], ascending=True)\n",
    "to_clear_sell_orders = sell_auction_orderbook[available_sell_orders].sort_values(by=[\"Timestamp\"], ascending=True)\n",
    "\n",
    "agg_buy_qty = to_clear_buy_orders[\"Quantity\"].sum()\n",
    "agg_sell_qty = to_clear_sell_orders[\"Quantity\"].sum()\n",
    "if agg_buy_qty == agg_sell_qty:\n",
    "    type_clear = \"equal\"\n",
    "elif agg_buy_qty > agg_sell_qty:\n",
    "    type_clear = \"buy_excess\"\n",
    "elif agg_buy_qty < agg_sell_qty:\n",
    "    type_clear = \"sell_excess\"\n",
    "\n",
    "# initiate clearing process\n",
    "df_participants, transaction_log, open_auction_log = matching_logic(df_participants, to_clear_buy_orders, to_clear_sell_orders, type_clear, open_auction_log)\n",
    "# change status of all remaning open orders to be unmatched\n",
    "open_auction_log.loc[open_auction_log['Status'] == 'Open', 'Status'] = 'Not Matched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_auction_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mopen_auction_log\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'open_auction_log' is not defined"
     ]
    }
   ],
   "source": [
    "open_auction_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
